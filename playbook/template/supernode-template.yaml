---
# åŠŸèƒ½è¯´æ˜ï¼šè…¾è®¯äº‘è¶…çº§èŠ‚ç‚¹æ¼”ç»ƒæ¨¡æ¿
# æ”¯æŒçš„æ¼”ç»ƒåœºæ™¯ï¼š
# 1. schedule-pressure: è¶…çº§èŠ‚ç‚¹Podè°ƒåº¦å‹åŠ›æµ‹è¯•
# 2. resource-limit: è¶…çº§èŠ‚ç‚¹èµ„æºé™åˆ¶æµ‹è¯•
# 3. failure-simulation: è¶…çº§èŠ‚ç‚¹æ•…éšœæ¨¡æ‹Ÿæµ‹è¯•
apiVersion: argoproj.io/v1alpha1
kind: ClusterWorkflowTemplate
metadata:
  name: supernode-template
spec:
  entrypoint: main
  serviceAccountName: tke-chaos
  templates:
  - name: main
    inputs:
      parameters:
      - name: cluster-id
        description: "æ¼”ç»ƒé›†ç¾¤ID"
      - name: webhook-url
        description: "ä¼ä¸šå¾®ä¿¡ç¾¤webhookåœ°å€"
        default: ""
      - name: chaos-type
        description: "æ¼”ç»ƒç±»å‹"
        default: "supernode chaos test"
      - name: scenario-type
        description: "æ¼”ç»ƒåœºæ™¯ç±»å‹: schedule-pressure/resource-limit/failure-simulation"
      - name: supernode-selector
        description: "è¶…çº§èŠ‚ç‚¹é€‰æ‹©å™¨ï¼Œå¦‚: node.kubernetes.io/instance-type=eklet"
        default: "node.kubernetes.io/instance-type=eklet"
      - name: test-duration
        description: "æµ‹è¯•æŒç»­æ—¶é—´"
        default: "60s"
      - name: test-pod-count
        description: "æµ‹è¯•Podæ•°é‡"
        default: "50"
      - name: cpu-stress-cores
        description: "CPUå‹åŠ›æµ‹è¯•æ ¸å¿ƒæ•°"
        default: "2"
      - name: memory-stress-size
        description: "å†…å­˜å‹åŠ›æµ‹è¯•å¤§å°"
        default: "1G"
      - name: kubeconfig-secret-name
        description: "ç›®æ ‡é›†ç¾¤kubeconfig secretåç§°"
      - name: precheck-cluster-image
        description: "å‰ç½®æ£€æŸ¥å·¥å…·é•œåƒ"
      - name: check-configmap-name
        default: "tke-chaos-precheck-resource"
      - name: check-configmap-namespace
        default: "tke-chaos-test"
      - name: pods-health-ratio
        description: "Podå¥åº·ç‡é˜ˆå€¼"
        default: "0.9"
      - name: nodes-health-ratio
        description: "èŠ‚ç‚¹å¥åº·ç‡é˜ˆå€¼"
        default: "0.9"
    steps:
    - - name: notify-start
        arguments:
          parameters:
          - name: webhook-url
            value: "{{inputs.parameters.webhook-url}}"
          - name: cluster-id
            value: "{{inputs.parameters.cluster-id}}"
          - name: chaos-type
            value: "{{inputs.parameters.chaos-type}}"
          - name: scenario-type
            value: "{{inputs.parameters.scenario-type}}"
          - name: action
            value: "start"
        template: notify
        when: "'{{inputs.parameters.webhook-url}}' != ''"
    
    - - name: precheck
        arguments:
          parameters:
          - name: kubeconfig-secret-name
            value: "{{inputs.parameters.kubeconfig-secret-name}}"
          - name: precheck-cluster-image
            value: "{{inputs.parameters.precheck-cluster-image}}"
          - name: check-configmap-name
            value: "{{inputs.parameters.check-configmap-name}}"
          - name: check-configmap-namespace
            value: "{{inputs.parameters.check-configmap-namespace}}"
          - name: pods-health-ratio
            value: "{{inputs.parameters.pods-health-ratio}}"
          - name: nodes-health-ratio
            value: "{{inputs.parameters.nodes-health-ratio}}"
          - name: supernode-selector
            value: "{{inputs.parameters.supernode-selector}}"
        template: precheck
    
    - - name: execute-scenario
        arguments:
          parameters:
          - name: scenario-type
            value: "{{inputs.parameters.scenario-type}}"
          - name: supernode-selector
            value: "{{inputs.parameters.supernode-selector}}"
          - name: test-duration
            value: "{{inputs.parameters.test-duration}}"
          - name: test-pod-count
            value: "{{inputs.parameters.test-pod-count}}"
          - name: cpu-stress-cores
            value: "{{inputs.parameters.cpu-stress-cores}}"
          - name: memory-stress-size
            value: "{{inputs.parameters.memory-stress-size}}"
          - name: kubeconfig-secret-name
            value: "{{inputs.parameters.kubeconfig-secret-name}}"
        template: execute-scenario
    
    - - name: cleanup
        arguments:
          parameters:
          - name: kubeconfig-secret-name
            value: "{{inputs.parameters.kubeconfig-secret-name}}"
        template: cleanup
    
    - - name: notify-end
        arguments:
          parameters:
          - name: webhook-url
            value: "{{inputs.parameters.webhook-url}}"
          - name: cluster-id
            value: "{{inputs.parameters.cluster-id}}"
          - name: chaos-type
            value: "{{inputs.parameters.chaos-type}}"
          - name: scenario-type
            value: "{{inputs.parameters.scenario-type}}"
          - name: action
            value: "end"
        template: notify
        when: "'{{inputs.parameters.webhook-url}}' != ''"

  - name: precheck
    inputs:
      parameters:
      - name: kubeconfig-secret-name
      - name: precheck-cluster-image
      - name: check-configmap-name
      - name: check-configmap-namespace
      - name: pods-health-ratio
      - name: nodes-health-ratio
      - name: supernode-selector
    script:
      image: "{{inputs.parameters.precheck-cluster-image}}"
      command: [bash]
      source: |
        #!/bin/bash
        set -e
        
        echo "å¼€å§‹è¶…çº§èŠ‚ç‚¹æ¼”ç»ƒå‰ç½®æ£€æŸ¥..."
        
        # æ£€æŸ¥é›†ç¾¤ä¸­æ˜¯å¦å­˜åœ¨è¶…çº§èŠ‚ç‚¹
        SUPERNODE_COUNT=$(kubectl get nodes -l "{{inputs.parameters.supernode-selector}}" --no-headers 2>/dev/null | wc -l)
        if [ "$SUPERNODE_COUNT" -eq 0 ]; then
          echo "é”™è¯¯: é›†ç¾¤ä¸­æœªæ‰¾åˆ°è¶…çº§èŠ‚ç‚¹ (selector: {{inputs.parameters.supernode-selector}})"
          exit 1
        fi
        echo "å‘ç° $SUPERNODE_COUNT ä¸ªè¶…çº§èŠ‚ç‚¹"
        
        # æ£€æŸ¥é¢„æ£€æŸ¥èµ„æº
        kubectl get -n "{{inputs.parameters.check-configmap-namespace}}" configmap "{{inputs.parameters.check-configmap-name}}" > /dev/null
        echo "é¢„æ£€æŸ¥èµ„æºéªŒè¯é€šè¿‡"
        
        # æ£€æŸ¥é›†ç¾¤å¥åº·çŠ¶æ€
        TOTAL_PODS=$(kubectl get pods --all-namespaces --no-headers 2>/dev/null | wc -l)
        RUNNING_PODS=$(kubectl get pods --all-namespaces --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)
        
        if [ "$TOTAL_PODS" -gt 0 ]; then
          POD_HEALTH_RATIO=$(echo "scale=2; $RUNNING_PODS / $TOTAL_PODS" | bc -l)
          REQUIRED_RATIO={{inputs.parameters.pods-health-ratio}}
          if (( $(echo "$POD_HEALTH_RATIO < $REQUIRED_RATIO" | bc -l) )); then
            echo "é”™è¯¯: Podå¥åº·ç‡ ($POD_HEALTH_RATIO) ä½äºè¦æ±‚ ($REQUIRED_RATIO)"
            exit 1
          fi
          echo "Podå¥åº·ç‡æ£€æŸ¥é€šè¿‡: $POD_HEALTH_RATIO"
        fi
        
        TOTAL_NODES=$(kubectl get nodes --no-headers 2>/dev/null | wc -l)
        READY_NODES=$(kubectl get nodes --no-headers 2>/dev/null | grep " Ready " | wc -l)
        
        if [ "$TOTAL_NODES" -gt 0 ]; then
          NODE_HEALTH_RATIO=$(echo "scale=2; $READY_NODES / $TOTAL_NODES" | bc -l)
          REQUIRED_RATIO={{inputs.parameters.nodes-health-ratio}}
          if (( $(echo "$NODE_HEALTH_RATIO < $REQUIRED_RATIO" | bc -l) )); then
            echo "é”™è¯¯: èŠ‚ç‚¹å¥åº·ç‡ ($NODE_HEALTH_RATIO) ä½äºè¦æ±‚ ($REQUIRED_RATIO)"
            exit 1
          fi
          echo "èŠ‚ç‚¹å¥åº·ç‡æ£€æŸ¥é€šè¿‡: $NODE_HEALTH_RATIO"
        fi
        
        echo "è¶…çº§èŠ‚ç‚¹æ¼”ç»ƒå‰ç½®æ£€æŸ¥å®Œæˆ"
      volumeMounts:
      - name: kubeconfig
        mountPath: /root/.kube
      volumes:
      - name: kubeconfig
        secret:
          secretName: "{{inputs.parameters.kubeconfig-secret-name}}"

  - name: notify
    inputs:
      parameters:
      - name: webhook-url
      - name: cluster-id
      - name: chaos-type
      - name: scenario-type
      - name: action
    script:
      image: "curlimages/curl:7.85.0"
      command: [sh]
      source: |
        #!/bin/sh
        if [ "{{inputs.parameters.webhook-url}}" = "" ]; then
          echo "webhook-urlä¸ºç©ºï¼Œè·³è¿‡é€šçŸ¥"
          exit 0
        fi
        
        ACTION="{{inputs.parameters.action}}"
        if [ "$ACTION" = "start" ]; then
          MESSAGE="ğŸš€ è¶…çº§èŠ‚ç‚¹æ¼”ç»ƒå¼€å§‹\né›†ç¾¤ID: {{inputs.parameters.cluster-id}}\næ¼”ç»ƒç±»å‹: {{inputs.parameters.chaos-type}}\næ¼”ç»ƒåœºæ™¯: {{inputs.parameters.scenario-type}}"
        else
          MESSAGE="âœ… è¶…çº§èŠ‚ç‚¹æ¼”ç»ƒç»“æŸ\né›†ç¾¤ID: {{inputs.parameters.cluster-id}}\næ¼”ç»ƒç±»å‹: {{inputs.parameters.chaos-type}}\næ¼”ç»ƒåœºæ™¯: {{inputs.parameters.scenario-type}}"
        fi
        
        curl -X POST "{{inputs.parameters.webhook-url}}" \
          -H "Content-Type: application/json" \
          -d "{\"msgtype\":\"text\",\"text\":{\"content\":\"$MESSAGE\"}}"

  - name: execute-scenario
    inputs:
      parameters:
      - name: scenario-type
      - name: supernode-selector
      - name: test-duration
      - name: test-pod-count
      - name: cpu-stress-cores
      - name: memory-stress-size
      - name: kubeconfig-secret-name
    dag:
      tasks:
      - name: schedule-pressure-test
        arguments:
          parameters:
          - name: supernode-selector
            value: "{{inputs.parameters.supernode-selector}}"
          - name: test-duration
            value: "{{inputs.parameters.test-duration}}"
          - name: test-pod-count
            value: "{{inputs.parameters.test-pod-count}}"
          - name: kubeconfig-secret-name
            value: "{{inputs.parameters.kubeconfig-secret-name}}"
        template: schedule-pressure-test
        when: "'{{inputs.parameters.scenario-type}}' == 'schedule-pressure'"
      
      - name: resource-limit-test
        arguments:
          parameters:
          - name: supernode-selector
            value: "{{inputs.parameters.supernode-selector}}"
          - name: test-duration
            value: "{{inputs.parameters.test-duration}}"
          - name: cpu-stress-cores
            value: "{{inputs.parameters.cpu-stress-cores}}"
          - name: memory-stress-size
            value: "{{inputs.parameters.memory-stress-size}}"
          - name: kubeconfig-secret-name
            value: "{{inputs.parameters.kubeconfig-secret-name}}"
        template: resource-limit-test
        when: "'{{inputs.parameters.scenario-type}}' == 'resource-limit'"
      
      - name: failure-simulation-test
        arguments:
          parameters:
          - name: supernode-selector
            value: "{{inputs.parameters.supernode-selector}}"
          - name: test-duration
            value: "{{inputs.parameters.test-duration}}"
          - name: kubeconfig-secret-name
            value: "{{inputs.parameters.kubeconfig-secret-name}}"
        template: failure-simulation-test
        when: "'{{inputs.parameters.scenario-type}}' == 'failure-simulation'"

  - name: schedule-pressure-test
    inputs:
      parameters:
      - name: supernode-selector
      - name: test-duration
      - name: test-pod-count
      - name: kubeconfig-secret-name
    script:
      image: "bitnami/kubectl:1.32.4"
      command: [bash]
      source: |
        #!/bin/bash
        set -e
        
        echo "å¼€å§‹è¶…çº§èŠ‚ç‚¹è°ƒåº¦å‹åŠ›æµ‹è¯•..."
        echo "ç›®æ ‡è¶…çº§èŠ‚ç‚¹é€‰æ‹©å™¨: {{inputs.parameters.supernode-selector}}"
        echo "æµ‹è¯•Podæ•°é‡: {{inputs.parameters.test-pod-count}}"
        echo "æµ‹è¯•æŒç»­æ—¶é—´: {{inputs.parameters.test-duration}}"
        
        # åˆ›å»ºæµ‹è¯•å‘½åç©ºé—´
        kubectl create namespace tke-supernode-test || true
        
        # è§£æè¶…çº§èŠ‚ç‚¹é€‰æ‹©å™¨
        SELECTOR_KEY=$(echo "{{inputs.parameters.supernode-selector}}" | cut -d'=' -f1)
        SELECTOR_VALUE=$(echo "{{inputs.parameters.supernode-selector}}" | cut -d'=' -f2)
        
        # æ‰¹é‡åˆ›å»ºPodåˆ°è¶…çº§èŠ‚ç‚¹
        POD_COUNT={{inputs.parameters.test-pod-count}}
        for i in $(seq 1 $POD_COUNT); do
          cat <<EOF | kubectl apply -f -
        apiVersion: v1
        kind: Pod
        metadata:
          name: supernode-test-pod-$i
          namespace: tke-supernode-test
          labels:
            test: supernode-pressure
            batch: pressure-test
        spec:
          nodeSelector:
            $SELECTOR_KEY: $SELECTOR_VALUE
          containers:
          - name: test-container
            image: nginx:alpine
            resources:
              requests:
                cpu: 100m
                memory: 128Mi
              limits:
                cpu: 200m
                memory: 256Mi
          restartPolicy: Never
        EOF
        done
        
        echo "å·²åˆ›å»º $POD_COUNT ä¸ªæµ‹è¯•Podï¼Œç­‰å¾…è°ƒåº¦..."
        
        # ç­‰å¾…Podè°ƒåº¦å®Œæˆ
        sleep 30
        
        # æ£€æŸ¥è°ƒåº¦ç»“æœ
        SCHEDULED_PODS=$(kubectl get pods -n tke-supernode-test -l test=supernode-pressure --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)
        TOTAL_PODS=$(kubectl get pods -n tke-supernode-test -l test=supernode-pressure --no-headers 2>/dev/null | wc -l)
        
        echo "è°ƒåº¦ç»“æœ: $SCHEDULED_PODS/$TOTAL_PODS ä¸ªPodæˆåŠŸè°ƒåº¦åˆ°è¶…çº§èŠ‚ç‚¹"
        
        # æ˜¾ç¤ºè¶…çº§èŠ‚ç‚¹ä¸Šçš„Podåˆ†å¸ƒ
        echo "è¶…çº§èŠ‚ç‚¹Podåˆ†å¸ƒæƒ…å†µ:"
        kubectl get pods -n tke-supernode-test -l test=supernode-pressure -o wide 2>/dev/null | head -10
        
        # æŒç»­ç›‘æ§æŒ‡å®šæ—¶é—´
        echo "å¼€å§‹ç›‘æ§ {{inputs.parameters.test-duration}}..."
        
        # è½¬æ¢æ—¶é—´æ ¼å¼ (å¦‚ 60s -> 60)
        DURATION_SECONDS=$(echo "{{inputs.parameters.test-duration}}" | sed 's/s$//')
        sleep $DURATION_SECONDS
        
        # æœ€ç»ˆçŠ¶æ€æ£€æŸ¥
        FINAL_RUNNING=$(kubectl get pods -n tke-supernode-test -l test=supernode-pressure --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)
        echo "æµ‹è¯•ç»“æŸæ—¶è¿è¡Œä¸­çš„Podæ•°é‡: $FINAL_RUNNING"
        
        echo "è¶…çº§èŠ‚ç‚¹è°ƒåº¦å‹åŠ›æµ‹è¯•å®Œæˆ"
      volumeMounts:
      - name: kubeconfig
        mountPath: /root/.kube
      volumes:
      - name: kubeconfig
        secret:
          secretName: "{{inputs.parameters.kubeconfig-secret-name}}"

  - name: resource-limit-test
    inputs:
      parameters:
      - name: supernode-selector
      - name: test-duration
      - name: cpu-stress-cores
      - name: memory-stress-size
      - name: kubeconfig-secret-name
    script:
      image: "bitnami/kubectl:1.32.4"
      command: [bash]
      source: |
        #!/bin/bash
        set -e
        
        echo "å¼€å§‹è¶…çº§èŠ‚ç‚¹èµ„æºé™åˆ¶æµ‹è¯•..."
        echo "CPUå‹åŠ›æ ¸å¿ƒæ•°: {{inputs.parameters.cpu-stress-cores}}"
        echo "å†…å­˜å‹åŠ›å¤§å°: {{inputs.parameters.memory-stress-size}}"
        
        # åˆ›å»ºæµ‹è¯•å‘½åç©ºé—´
        kubectl create namespace tke-supernode-test || true
        
        # è§£æè¶…çº§èŠ‚ç‚¹é€‰æ‹©å™¨
        SELECTOR_KEY=$(echo "{{inputs.parameters.supernode-selector}}" | cut -d'=' -f1)
        SELECTOR_VALUE=$(echo "{{inputs.parameters.supernode-selector}}" | cut -d'=' -f2)
        
        # åˆ›å»ºé«˜èµ„æºæ¶ˆè€—çš„Pod
        cat <<EOF | kubectl apply -f -
        apiVersion: v1
        kind: Pod
        metadata:
          name: supernode-resource-test
          namespace: tke-supernode-test
          labels:
            test: supernode-resource
        spec:
          nodeSelector:
            $SELECTOR_KEY: $SELECTOR_VALUE
          containers:
          - name: cpu-stress
            image: progrium/stress
            args: ["--cpu", "{{inputs.parameters.cpu-stress-cores}}", "--timeout", "{{inputs.parameters.test-duration}}"]
            resources:
              requests:
                cpu: "{{inputs.parameters.cpu-stress-cores}}000m"
                memory: "{{inputs.parameters.memory-stress-size}}"
              limits:
                cpu: "4000m"
                memory: "2Gi"
          - name: memory-stress
            image: progrium/stress
            args: ["--vm", "1", "--vm-bytes", "{{inputs.parameters.memory-stress-size}}", "--timeout", "{{inputs.parameters.test-duration}}"]
            resources:
              requests:
                memory: "{{inputs.parameters.memory-stress-size}}"
              limits:
                memory: "2Gi"
        EOF
        
        echo "å·²åˆ›å»ºèµ„æºå‹åŠ›æµ‹è¯•Podï¼Œç›‘æ§æ‰§è¡Œæƒ…å†µ..."
        
        # ç›‘æ§PodçŠ¶æ€
        kubectl wait --for=condition=Ready pod/supernode-resource-test -n tke-supernode-test --timeout=60s || {
          echo "è­¦å‘Š: èµ„æºå‹åŠ›æµ‹è¯•Podæœªèƒ½æ­£å¸¸å¯åŠ¨"
          kubectl describe pod supernode-resource-test -n tke-supernode-test
        }
        
        # è½¬æ¢æ—¶é—´æ ¼å¼
        DURATION_SECONDS=$(echo "{{inputs.parameters.test-duration}}" | sed 's/s$//')
        sleep $DURATION_SECONDS
        
        echo "è¶…çº§èŠ‚ç‚¹èµ„æºé™åˆ¶æµ‹è¯•å®Œæˆ"
      volumeMounts:
      - name: kubeconfig
        mountPath: /root/.kube
      volumes:
      - name: kubeconfig
        secret:
          secretName: "{{inputs.parameters.kubeconfig-secret-name}}"

  - name: failure-simulation-test
    inputs:
      parameters:
      - name: supernode-selector
      - name: test-duration
      - name: kubeconfig-secret-name
    script:
      image: "bitnami/kubectl:1.32.4"
      command: [bash]
      source: |
        #!/bin/bash
        set -e
        
        echo "å¼€å§‹è¶…çº§èŠ‚ç‚¹æ•…éšœæ¨¡æ‹Ÿæµ‹è¯•..."
        
        # åˆ›å»ºæµ‹è¯•å‘½åç©ºé—´
        kubectl create namespace tke-supernode-test || true
        
        # è§£æè¶…çº§èŠ‚ç‚¹é€‰æ‹©å™¨
        SELECTOR_KEY=$(echo "{{inputs.parameters.supernode-selector}}" | cut -d'=' -f1)
        SELECTOR_VALUE=$(echo "{{inputs.parameters.supernode-selector}}" | cut -d'=' -f2)
        
        # åˆ›å»ºä¼šå¯¼è‡´Podå¤±è´¥çš„æµ‹è¯•
        cat <<EOF | kubectl apply -f -
        apiVersion: v1
        kind: Pod
        metadata:
          name: supernode-failure-test-1
          namespace: tke-supernode-test
          labels:
            test: supernode-failure
        spec:
          nodeSelector:
            $SELECTOR_KEY: $SELECTOR_VALUE
          containers:
          - name: exit-container
            image: busybox
            command: ["sh", "-c", "echo 'Testing failure scenario'; sleep 10; exit 1"]
          restartPolicy: Never
        ---
        apiVersion: v1
        kind: Pod
        metadata:
          name: supernode-failure-test-2
          namespace: tke-supernode-test
          labels:
            test: supernode-failure
        spec:
          nodeSelector:
            $SELECTOR_KEY: $SELECTOR_VALUE
          containers:
          - name: oom-container
            image: progrium/stress
            args: ["--vm", "1", "--vm-bytes", "10G", "--timeout", "30s"]
            resources:
              limits:
                memory: "1Gi"
          restartPolicy: Never
        EOF
        
        echo "å·²åˆ›å»ºæ•…éšœæ¨¡æ‹Ÿæµ‹è¯•Podï¼Œè§‚å¯Ÿè¶…çº§èŠ‚ç‚¹å¤„ç†å¼‚å¸¸Podçš„è¡Œä¸º..."
        
        # è½¬æ¢æ—¶é—´æ ¼å¼
        DURATION_SECONDS=$(echo "{{inputs.parameters.test-duration}}" | sed 's/s$//')
        sleep $DURATION_SECONDS
        
        # æ£€æŸ¥PodçŠ¶æ€
        echo "æ•…éšœæµ‹è¯•PodçŠ¶æ€:"
        kubectl get pods -n tke-supernode-test -l test=supernode-failure -o wide
        
        echo "è¶…çº§èŠ‚ç‚¹æ•…éšœæ¨¡æ‹Ÿæµ‹è¯•å®Œæˆ"
      volumeMounts:
      - name: kubeconfig
        mountPath: /root/.kube
      volumes:
      - name: kubeconfig
        secret:
          secretName: "{{inputs.parameters.kubeconfig-secret-name}}"

  - name: cleanup
    inputs:
      parameters:
      - name: kubeconfig-secret-name
    script:
      image: "bitnami/kubectl:1.32.4"
      command: [bash]
      source: |
        #!/bin/bash
        echo "å¼€å§‹æ¸…ç†è¶…çº§èŠ‚ç‚¹æµ‹è¯•èµ„æº..."
        
        # åˆ é™¤æµ‹è¯•å‘½åç©ºé—´åŠæ‰€æœ‰èµ„æº
        kubectl delete namespace tke-supernode-test --ignore-not-found=true
        
        echo "è¶…çº§èŠ‚ç‚¹æµ‹è¯•èµ„æºæ¸…ç†å®Œæˆ"
      volumeMounts:
      - name: kubeconfig
        mountPath: /root/.kube
      volumes:
      - name: kubeconfig
        secret:
          secretName: "{{inputs.parameters.kubeconfig-secret-name}}"