---
# 腾讯云超级节点演练模板
# 基于workload-disruption-template的成功模式构建
apiVersion: argoproj.io/v1alpha1
kind: ClusterWorkflowTemplate
metadata:
  name: supernode-template
spec:
  entrypoint: main
  serviceAccountName: tke-chaos
  templates:
  - name: main
    inputs:
      parameters:
      - name: scenario-type
        description: "演练场景类型: schedule-pressure/resource-limit"
        default: "schedule-pressure"
      - name: supernode-selector
        description: "超级节点选择器"
        default: "kubernetes.io/os=linux"
      - name: test-duration
        description: "测试持续时间"
        default: "60s"
      - name: test-pod-count
        description: "测试Pod数量"
        default: "10"
      - name: kubeconfig-secret-name
        description: "目标集群kubeconfig secret名称"
      - name: precheck-configmap-name
        default: "tke-chaos-precheck-resource"
        description: "预检查配置configmap名称"
      - name: precheck-configmap-namespace
        default: "tke-chaos-test"
        description: "预检查配置configmap所在命名空间"
    steps:
    - - name: precheck
        arguments:
          parameters:
          - name: kubeconfig-secret-name
            value: "{{inputs.parameters.kubeconfig-secret-name}}"
          - name: source
            value: |
              # 检查预检查资源
              kubectl get -n {{inputs.parameters.precheck-configmap-namespace}} configmap {{inputs.parameters.precheck-configmap-name}}
              
              # 检查超级节点
              echo "检查超级节点 (selector: {{inputs.parameters.supernode-selector}})..."
              SUPERNODE_COUNT=$(kubectl get nodes -l "{{inputs.parameters.supernode-selector}}" --no-headers 2>/dev/null | wc -l)
              if [ "$SUPERNODE_COUNT" -eq 0 ]; then
                echo "错误: 集群中未找到超级节点 (selector: {{inputs.parameters.supernode-selector}})"
                exit 1
              fi
              echo "发现 $SUPERNODE_COUNT 个超级节点"
              kubectl get nodes -l "{{inputs.parameters.supernode-selector}}"
        templateRef:
          name: kubectl-cmd
          template: kubectl-script
          clusterScope: true
    
    - - name: execute-test
        arguments:
          parameters:
          - name: scenario-type
            value: "{{inputs.parameters.scenario-type}}"
          - name: supernode-selector
            value: "{{inputs.parameters.supernode-selector}}"
          - name: test-duration
            value: "{{inputs.parameters.test-duration}}"
          - name: test-pod-count
            value: "{{inputs.parameters.test-pod-count}}"
          - name: kubeconfig-secret-name
            value: "{{inputs.parameters.kubeconfig-secret-name}}"
        template: execute-test
    
    - - name: cleanup
        arguments:
          parameters:
          - name: kubeconfig-secret-name
            value: "{{inputs.parameters.kubeconfig-secret-name}}"
          - name: source
            value: |
              echo "清理超级节点测试资源..."
              kubectl delete namespace tke-supernode-test --ignore-not-found=true
              echo "清理完成"
        templateRef:
          name: kubectl-cmd
          template: kubectl-script
          clusterScope: true

  - name: execute-test
    inputs:
      parameters:
      - name: scenario-type
      - name: supernode-selector
      - name: test-duration
      - name: test-pod-count
      - name: kubeconfig-secret-name
    dag:
      tasks:
      - name: schedule-pressure-test
        arguments:
          parameters:
          - name: kubeconfig-secret-name
            value: "{{inputs.parameters.kubeconfig-secret-name}}"
          - name: source
            value: |
              echo "开始超级节点调度压力测试..."
              echo "目标选择器: {{inputs.parameters.supernode-selector}}"
              echo "测试Pod数量: {{inputs.parameters.test-pod-count}}"
              
              # 创建测试命名空间
              kubectl create namespace tke-supernode-test || true
              
              # 解析选择器
              SELECTOR_KEY=$(echo "{{inputs.parameters.supernode-selector}}" | cut -d'=' -f1)
              SELECTOR_VALUE=$(echo "{{inputs.parameters.supernode-selector}}" | cut -d'=' -f2)
              
              # 创建测试Pod
              POD_COUNT={{inputs.parameters.test-pod-count}}
              for i in $(seq 1 $POD_COUNT); do
                cat <<EOF | kubectl apply -f -
              apiVersion: v1
              kind: Pod
              metadata:
                name: supernode-test-pod-$i
                namespace: tke-supernode-test
                labels:
                  test: supernode-pressure
              spec:
                nodeSelector:
                  $SELECTOR_KEY: $SELECTOR_VALUE
                containers:
                - name: test-container
                  image: nginx:alpine
                  resources:
                    requests:
                      cpu: 100m
                      memory: 128Mi
                    limits:
                      cpu: 200m
                      memory: 256Mi
                restartPolicy: Never
              EOF
              done
              
              echo "已创建 $POD_COUNT 个测试Pod，等待调度..."
              sleep 30
              
              # 检查调度结果
              SCHEDULED_PODS=$(kubectl get pods -n tke-supernode-test -l test=supernode-pressure --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)
              TOTAL_PODS=$(kubectl get pods -n tke-supernode-test -l test=supernode-pressure --no-headers 2>/dev/null | wc -l)
              
              echo "调度结果: $SCHEDULED_PODS/$TOTAL_PODS 个Pod成功调度"
              kubectl get pods -n tke-supernode-test -l test=supernode-pressure -o wide
              
              # 等待测试时间
              DURATION_SECONDS=$(echo "{{inputs.parameters.test-duration}}" | sed 's/s$//')
              sleep $DURATION_SECONDS
              
              echo "超级节点调度压力测试完成"
        templateRef:
          name: kubectl-cmd
          template: kubectl-script
          clusterScope: true
        when: "'{{inputs.parameters.scenario-type}}' == 'schedule-pressure'"
      
      - name: resource-limit-test
        arguments:
          parameters:
          - name: kubeconfig-secret-name
            value: "{{inputs.parameters.kubeconfig-secret-name}}"
          - name: source
            value: |
              echo "开始超级节点资源限制测试..."
              
              # 创建测试命名空间
              kubectl create namespace tke-supernode-test || true
              
              # 解析选择器
              SELECTOR_KEY=$(echo "{{inputs.parameters.supernode-selector}}" | cut -d'=' -f1)
              SELECTOR_VALUE=$(echo "{{inputs.parameters.supernode-selector}}" | cut -d'=' -f2)
              
              # 创建资源压力测试Pod
              cat <<EOF | kubectl apply -f -
              apiVersion: v1
              kind: Pod
              metadata:
                name: supernode-resource-test
                namespace: tke-supernode-test
                labels:
                  test: supernode-resource
              spec:
                nodeSelector:
                  $SELECTOR_KEY: $SELECTOR_VALUE
                containers:
                - name: cpu-stress
                  image: progrium/stress
                  args: ["--cpu", "2", "--timeout", "{{inputs.parameters.test-duration}}"]
                  resources:
                    requests:
                      cpu: 1000m
                      memory: 512Mi
                    limits:
                      cpu: 2000m
                      memory: 1Gi
              EOF
              
              echo "已创建资源压力测试Pod，监控执行情况..."
              
              # 等待测试时间
              DURATION_SECONDS=$(echo "{{inputs.parameters.test-duration}}" | sed 's/s$//')
              sleep $DURATION_SECONDS
              
              kubectl get pod supernode-resource-test -n tke-supernode-test -o wide
              echo "超级节点资源限制测试完成"
        templateRef:
          name: kubectl-cmd
          template: kubectl-script
          clusterScope: true
        when: "'{{inputs.parameters.scenario-type}}' == 'resource-limit'"